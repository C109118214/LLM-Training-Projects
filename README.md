# LLM-Training-Projects
✅ LLM → Hugging Face 微調小型模型，嘗試 PEFT/LoRA 技術

📌 1. 嘗試訓練 LLM Pretrain
🔹 目標：
使用 Hugging Face 訓練小型 LLM (如 GPT-2, LLaMA-2-7B)

✅ 方法：

#### 1. 下載 Hugging Face 預訓練模型

#### 2. 準備語料 (使用 OpenWebText, WikiText-103 等)

#### 3. 進行 Pretraining

#### 4. 儲存模型，進行推理測試
